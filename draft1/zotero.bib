@Article{ibrahim_bayesian_2015,
  title = {Bayesian probability of success for clinical trials using historical data},
  volume = {34},
  issn = {0277-6715},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4676938/},
  doi = {10.1002/sim.6339},
  abstract = {Developing sophisticated statistical methods for go/no-go decisions is crucial for clinical trials, as planning phase III or phase IV trials is costly and time consuming. In this paper, we develop a novel Bayesian methodology for determining the probability of success of a treatment regimen on the basis of the current data of a given trial. We introduce a new criterion for calculating the probability of success that allows for inclusion of covariates as well as allowing for historical data based on the treatment regimen, and patient characteristics. A new class of prior distributions and covariate distributions is developed to achieve this goal. The methodology is quite general and can be used with univariate or multivariate continuous or discrete data, and it generalizes Chuang-Stein’s work. This methodology will be invaluable for informing the scientist on the likelihood of success of the compound, while including the information of covariates for patient characteristics in the trial population for planning future pre-market or post-market trials.},
  number = {2},
  urldate = {2017-11-28TZ},
  journal = {Statistics in medicine},
  author = {Joseph G. Ibrahim and Ming-Hui Chen and Mani Lakshminarayanan and Guanghan F. Liu and Joseph F. Heyse},
  month = {jan},
  year = {2015},
  pmid = {25339499},
  pmcid = {PMC4676938},
  pages = {249--264},
}

@Article{chen_bayesian_2011,
  title = {Bayesian {Design} of {Non}-{Inferiority} {Trials} for {Medical} {Devices} {Using} {Historical} {Data}},
  volume = {67},
  issn = {0006-341X},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3136555/},
  doi = {10.1111/j.1541-0420.2011.01561.x},
  abstract = {We develop a new Bayesian approach of sample size determination (SSD) for the design of non-inferiority clinical trials. We extend the fitting and sampling priors of  to Bayesian SSD with a focus on controlling the type I error and power. Historical data are incorporated via a hierarchical modeling approach as well as the power prior approach of . Various properties of the proposed Bayesian SSD methodology are examined and a simulation-based computational algorithm is developed. The proposed methodology is applied to the design of a non-inferiority medical device clinical trial with historical data from previous trials.},
  number = {3},
  urldate = {2017-11-28TZ},
  journal = {Biometrics},
  author = {Ming-Hui Chen and Joseph G. Ibrahim and Peter Lam and Alan Yu and Yuanye Zhang},
  month = {sep},
  year = {2011},
  pmid = {21361889},
  pmcid = {PMC3136555},
  pages = {1163--1170},
}

@Article{jansen_bayesian_2017,
  title = {Bayesian clinical trial designs: {Another} option for trauma trials?},
  volume = {83},
  issn = {2163-0755},
  shorttitle = {Bayesian clinical trial designs},
  url = {http://Insights.ovid.com/crossref?an=01586154-201710000-00026},
  doi = {10.1097/TA.0000000000001638},
  language = {en},
  number = {4},
  urldate = {2017-11-28TZ},
  journal = {Journal of Trauma and Acute Care Surgery},
  author = {Jan O. Jansen and Philip Pallmann and Graeme MacLennan and Marion K. Campbell},
  month = {oct},
  year = {2017},
  pages = {736--741},
}

@Article{vincent_darc_2017,
  title = {The {DARC} {Toolbox}: automated, flexible, and efficient delayed and risky choice experiments using {Bayesian} adaptive design},
  shorttitle = {The {DARC} {Toolbox}},
  url = {https://psyarxiv.com/yehjb/},
  doi = {10.17605/OSF.IO/YEHJB},
  abstract = {Delayed and risky choice (DARC) experiments are a cornerstone of research in psychology, behavioural economics and neuroeconomics. By collecting an agent's preferences between pairs of prospects we can characterise their preferences, investigate what affects them, and probe the underlying decision making mechanisms. We present a state-of-the-art approach and software toolbox allowing such DARC experiments to be run in a highly efficient way. Data collection is costly, so our toolbox automatically and adaptively generates pairs of prospects in real time to maximise the information gathered about the participant's behaviours. We demonstrate that this leads to improvements over alternative experimental paradigms. The key to releasing our real time and automatic performance is a number of advances over current Bayesian adaptive design methodology. In particular, we derive an improved estimator for discrete output problems and design a novel algorithm for automating sequential adaptive design. We provide a number of pre-prepared DARC tools for researchers to use, but a key contribution is an adaptive experiment toolbox that can be extended to virtually any 2-alternative-choice tasks. In particular, to carry out custom adaptive experiments using our toolbox, the user need only encode their behavioural model and design space - both the subsequent inference and sequential design optimisation are automated for arbitrary models the user might write.},
  urldate = {2017-11-28TZ},
  journal = {PsyArXiv},
  author = {Benjamin T. Vincent and Tom Rainforth},
  month = {oct},
  year = {2017},
}

@Article{yin_phase_2012,
  title = {Phase {II} trial design with {Bayesian} adaptive randomization and predictive probability},
  volume = {61},
  issn = {0035-9254},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3832255/},
  doi = {10.1111/j.1467-9876.2011.01006.x},
  abstract = {We propose a randomized phase II clinical trial design based on Bayesian adaptive randomization and predictive probability monitoring. Adaptive randomization assigns more patients to a more efficacious treatment arm by comparing the posterior probabilities of efficacy between different arms. We continuously monitor the trial by using the predictive probability. The trial is terminated early when it is shown that one treatment is overwhelmingly superior to others or that all the treatments are equivalent. We develop two methods to compute the predictive probability by considering the uncertainty of the sample size of the future data. We illustrate the proposed Bayesian adaptive randomization and predictive probability design by using a phase II lung cancer clinical trial, and we conduct extensive simulation studies to examine the operating characteristics of the design. By coupling adaptive randomization and predictive probability approaches, the trial can treat more patients with a more efficacious treatment and allow for early stopping whenever sufficient information is obtained to conclude treatment superiority or equivalence. The design proposed also controls both the type I and the type II errors and offers an alternative Bayesian approach to the frequentist group sequential design.},
  number = {2},
  urldate = {2017-11-28TZ},
  journal = {Journal of the Royal Statistical Society. Series C, Applied statistics},
  author = {Guosheng Yin and Nan Chen and J. Jack Lee},
  month = {mar},
  year = {2012},
  pmid = {24259753},
  pmcid = {PMC3832255},
}

@Article{dong_bayesian-frequentist_2012,
  title = {A {Bayesian}-frequentist two-stage single-arm phase {II} clinical trial design},
  volume = {31},
  issn = {1097-0258},
  doi = {10.1002/sim.5330},
  abstract = {It is well-known that both frequentist and Bayesian clinical trial designs have their own advantages and disadvantages. To have better properties inherited from these two types of designs, we developed a Bayesian-frequentist two-stage single-arm phase II clinical trial design. This design allows both early acceptance and rejection of the null hypothesis ( H(0) ). The measures (for example probability of trial early termination, expected sample size, etc.) of the design properties under both frequentist and Bayesian settings are derived. Moreover, under the Bayesian setting, the upper and lower boundaries are determined with predictive probability of trial success outcome. Given a beta prior and a sample size for stage I, based on the marginal distribution of the responses at stage I, we derived Bayesian Type I and Type II error rates. By controlling both frequentist and Bayesian error rates, the Bayesian-frequentist two-stage design has special features compared with other two-stage designs.},
  language = {eng},
  number = {19},
  journal = {Statistics in Medicine},
  author = {Gaohong Dong and Weichung Joe Shih and Dirk Moore and Hui Quan and Stephen Marcella},
  month = {aug},
  year = {2012},
  pmid = {22415966},
  keywords = {Bayes Theorem, Bias, Binomial Distribution, Clinical Trials, Phase II as Topic, Data Interpretation, Statistical, Dose-Response Relationship, Drug, Endpoint Determination, Humans, Models, Statistical, Research Design, Sample Size},
  pages = {2055--2067},
}

@Article{teramukai_bayesian_2012,
  title = {A {Bayesian} predictive sample size selection design for single-arm exploratory clinical trials},
  volume = {31},
  issn = {1097-0258},
  doi = {10.1002/sim.5505},
  abstract = {The aim of an exploratory clinical trial is to determine whether a new intervention is promising for further testing in confirmatory clinical trials. Most exploratory clinical trials are designed as single-arm trials using a binary outcome with or without interim monitoring for early stopping. In this context, we propose a Bayesian adaptive design denoted as predictive sample size selection design (PSSD). The design allows for sample size selection following any planned interim analyses for early stopping of a trial, together with sample size determination before starting the trial. In the PSSD, we determine the sample size using the method proposed by Sambucini (Statistics in Medicine 2008; 27:1199-1224), which adopts a predictive probability criterion with two kinds of prior distributions, that is, an 'analysis prior' used to compute posterior probabilities and a 'design prior' used to obtain prior predictive distributions. In the sample size determination of the PSSD, we provide two sample sizes, that is, N and N(max) , using two types of design priors. At each interim analysis, we calculate the predictive probabilities of achieving a successful result at the end of the trial using the analysis prior in order to stop the trial in case of low or high efficacy (Lee et al., Clinical Trials 2008; 5:93-106), and we select an optimal sample size, that is, either N or N(max) as needed, on the basis of the predictive probabilities. We investigate the operating characteristics through simulation studies, and the PSSD retrospectively applies to a lung cancer clinical trial. (243)},
  language = {eng},
  number = {30},
  journal = {Statistics in Medicine},
  author = {Satoshi Teramukai and Takashi Daimon and Sarah Zohar},
  month = {dec},
  year = {2012},
  pmid = {22807115},
  keywords = {Bayes Theorem, Clinical Trials as Topic, Computer Simulation, Endpoint Determination, Humans, Neoplasms, Predictive Value of Tests, Research Design, Sample Size},
  pages = {4243--4254},
}

@Article{chen_bayesian_2014,
  title = {Bayesian {Design} of {Superiority} {Clinical} {Trials} for {Recurrent} {Events} {Data} with {Applications} to {Bleeding} and {Transfusion} {Events} in {Myelodyplastic} {Syndrome}},
  volume = {70},
  issn = {0006-341X},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4276515/},
  doi = {10.1111/biom.12215},
  abstract = {In many biomedical studies, patients may experience the same type of recurrent event repeatedly over time, such as bleeding, multiple infections and disease. In this article, we propose a Bayesian design to a pivotal clinical trial in which lower risk myelodysplastic syndromes (MDS) patients are treated with MDS disease modifying therapies. One of the key study objectives is to demonstrate the investigational product (treatment) effect on reduction of platelet transfusion and bleeding events while receiving MDS therapies. In this context, we propose a new Bayesian approach for the design of superiority clinical trials using recurrent events frailty regression models. Historical recurrent events data from an already completed phase 2 trial are incorporated into the Bayesian design via the partial borrowing power prior of , Biometrics
68, 578–586). An efficient Gibbs sampling algorithm, a predictive data generation algorithm, and a simulation-based algorithm are developed for sampling from the fitting posterior distribution, generating the predictive recurrent events data, and computing various design quantities such as the type I error rate and power, respectively. An extensive simulation study is conducted to compare the proposed method to the existing frequentist methods and to investigate various operating characteristics of the proposed design.},
  number = {4},
  urldate = {2017-11-28TZ},
  journal = {Biometrics},
  author = {Ming-Hui Chen and Joseph G. Ibrahim and Donglin Zeng and Kuolung Hu and Catherine Jia},
  month = {dec},
  year = {2014},
  pmid = {25041037},
  pmcid = {PMC4276515},
  pages = {1003--1013},
}

@Article{hobbs_bayesian_2016,
  title = {Bayesian {Group} {Sequential} {Clinical} {Trial} {Design} using {Total} {Toxicity} {Burden} and {Progression}-{Free} {Survival}},
  volume = {65},
  issn = {0035-9254},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4809549/},
  doi = {10.1111/rssc.12117},
  abstract = {Delivering radiation to eradicate a solid tumor while minimizing damage to nearby critical organs remains a challenge. For esophageal cancer, radiation therapy may damage the heart or lungs, and several qualitatively different, possibly recurrent toxicities associated with chemoradiation or surgery may occur, each at two or more possible grades. In this article, we describe a Bayesian group sequential clinical trial design, based on total toxicity burden (TTB) and progression-free survival duration, for comparing two radiation therapy modalities for esophageal cancer. Each patient’s toxicities are modeled as a multivariate doubly stochastic Poisson point process, with marks identifying toxicity grades. Each grade of each type of toxicity is assigned a severity weight, elicited from clinical oncologists familiar with the disease and treatments. TTB is defined as a severity-weighted sum over the different toxicities that may occur up to 12 months from the start of treatment. Latent frailties are used to formulate a multivariate model for all outcomes. Group sequential decision rules are based on posterior mean TTB and progression-free survival time. The proposed design is shown to provide both larger power and smaller mean sample size when compared to a conventional bivariate group sequential design.},
  number = {2},
  urldate = {2017-11-28TZ},
  journal = {Journal of the Royal Statistical Society. Series C, Applied statistics},
  author = {Brian P. Hobbs and Peter F. Thall and Steven H. Lin},
  month = {feb},
  year = {2016},
  pmid = {27034510},
  pmcid = {PMC4809549},
  pages = {273--297},
}

@Article{basu_hierarchical_2016,
  title = {A {Hierarchical} {Bayesian} {Approach} for {Combining} {Pharmacokinetic}/{Pharmacodynamic} {Modeling} and {Phase} {IIa} {Trial} {Design} in {Orphan} {Drugs}: {Treating} {Adrenoleukodystrophy} with {Lorenzo}’s {Oil}},
  volume = {26},
  issn = {1054-3406},
  shorttitle = {A {Hierarchical} {Bayesian} {Approach} for {Combining} {Pharmacokinetic}/{Pharmacodynamic} {Modeling} and {Phase} {IIa} {Trial} {Design} in {Orphan} {Drugs}},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5393457/},
  doi = {10.1080/10543406.2016.1226326},
  abstract = {X-linked adrenoleukodystrophy (X-ALD) is a rare, progressive and typically fatal neurodegenerative disease. Lorenzo’s Oil (LO) is one of the few X-ALD treatments available, but little has been done to establish its clinical efficacy or indications for its use. In this paper, we analyze data on 116 male asymptomatic pediatric patients who were administered LO. We offer a hierarchical Bayesian statistical approach to understanding LO pharmacokinetics (PK) and pharmacodynamics (PD) resulting from an accumulation of very long chain fatty acids. We experiment with individual- and observational-level errors, various choices of prior distributions, and deal with the limitation of having just one observation per administration of the drug, as opposed to the more usual multiple observations per administration. We link LO dose to the plasma erucic acid concentrations by PK modeling, and then link this concentration to a biomarker (C26, a very long chain fatty acid) by PD modeling. Next, we design a Bayesian Phase IIa study to estimate precisely what improvements in the biomarker can arise from various LO doses, while simultaneously modeling a binary toxicity endpoint. Our Bayesian adaptive algorithm emerges as reasonably robust and efficient while still retaining good classical (frequentist) operating characteristics. Future work looks toward using the results of this trial to design a Phase III study linking LO dose to actual improvements in health status, as measured by the appearance of brain lesions observed via magnetic resonance imaging.},
  number = {6},
  urldate = {2017-11-28TZ},
  journal = {Journal of biopharmaceutical statistics},
  author = {Cynthia Basu and Mariam A. Ahmed and Reena V. Kartha and Richard C. Brundage and Gerald V. Raymond and James C. Cloyd and Bradley P. Carlin},
  year = {2016},
  pmid = {27547896},
  pmcid = {PMC5393457},
  pages = {1025--1039},
}

@Article{trippa_bayesian_2017,
  title = {Bayesian {Baskets}: {A} {Novel} {Design} for {Biomarker}-{Based} {Clinical} {Trials}},
  volume = {35},
  issn = {1527-7755},
  shorttitle = {Bayesian {Baskets}},
  doi = {10.1200/JCO.2016.68.2864},
  abstract = {Purpose Biomarker-based clinical trials provide efficiencies during therapeutic development and form the foundation for precision medicine. These trials must generate information on both experimental therapeutics and putative predictive biomarkers in the context of varying pretrial information. We generated an efficient, flexible design that accommodates various pretrial levels of evidence supporting the predictive capacity of biomarkers while making pretrial design choices explicit. Methods We generated a randomization procedure that explicitly incorporates pretrial estimates of the predictive capacity of biomarkers. To compare the utility of this Bayesian basket (BB) design with that of a balanced randomized, biomarker agnostic (BA) design and a traditional basket (TB) design that includes only biomarker-positive patients, we iteratively simulated hypothetical multiarm clinical trials under various scenarios. Results BB was more efficient than BA while generating more information on the predictive capacity of putative biomarkers than both BA and TB. For simulations of hypothetical multiarm trials of experimental therapies and associated biomarkers of varying incident frequency, BB increased power over BA in cases when the biomarker was predictive and when the experimental therapeutic worked in all patients in a variety of scenarios. BB also generated more information about the predictive capacity of biomarkers than BA and categorically relative to TB, which generates no new biomarker information. Conclusion The BB design offers an efficient way to generate information on both experimental therapeutics and the predictive capacity of putative biomarkers. The design is flexible enough to accommodate varying levels of pretrial biomarker confidence within the same platform structure and makes clinical trial design decisions more explicit.},
  language = {eng},
  number = {6},
  journal = {Journal of Clinical Oncology: Official Journal of the American Society of Clinical Oncology},
  author = {Lorenzo Trippa and Brian Michael Alexander},
  month = {feb},
  year = {2017},
  pmid = {28045624},
  keywords = {Bayes Theorem, Biomarkers, Tumor, Computer Simulation, Humans, Neoplasms, Randomized Controlled Trials as Topic},
  pages = {681--687},
}

@Article{kim_lessons_2016,
  title = {Lessons learned from {BATTLE}-2 in the war on cancer: the use of {Bayesian} method in clinical trial design},
  volume = {4},
  issn = {2305-5839},
  shorttitle = {Lessons learned from {BATTLE}-2 in the war on cancer},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5220042/},
  doi = {10.21037/atm.2016.11.48},
  number = {23},
  urldate = {2017-11-28TZ},
  journal = {Annals of Translational Medicine},
  author = {Chul Kim and Giuseppe Giaccone},
  month = {dec},
  year = {2016},
  pmid = {28090522},
  pmcid = {PMC5220042},
}

@Article{bujacz_measuring_2014,
  title = {Measuring hedonia and eudaimonia as motives for activities: cross-national investigation through traditional and {Bayesian} structural equation modeling},
  volume = {5},
  issn = {1664-1078},
  shorttitle = {Measuring hedonia and eudaimonia as motives for activities},
  url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4157462/},
  doi = {10.3389/fpsyg.2014.00984},
  abstract = {Two major goals of this paper were, first to examine the cross-cultural consistency of the factor structure of the Hedonic and Eudaimonic Motives for Activities (HEMA) scale, and second to illustrate the advantages of using Bayesian estimation for such an examination. Bayesian estimation allows for more flexibility in model specification by making it possible to replace exact zero constraints (e.g., no cross-loadings) with approximate zero constraints (e.g., small cross-loadings). The stability of the constructs measured by the HEMA scale was tested across two national samples (Polish and North American) using both traditional and Bayesian estimation. First, a three-factor model (with hedonic pleasure, hedonic comfort and eudaimonic factors) was confirmed in both samples. Second, a model representing the metric invariance was tested. A traditional approach with maximum likelihood estimation reported a misfit of the model, leading to the acceptance of only a partial metric invariance structure. Bayesian estimation—that allowed for small and sample specific cross-loadings—endorsed the metric invariance model. The scalar invariance was not supported, therefore the comparison between latent factor means was not possible. Both traditional and Bayesian procedures revealed a similar latent factor correlation pattern within each of the national groups. The results suggest that the connection between hedonic and eudaimonic motives depends on which of the two hedonic dimensions is considered. In both groups the association between the eudaimonic factor and the hedonic comfort factor was weaker than the correlation between the hedonic pleasure factor and the eudaimonic factor. In summary, this paper explained the cross-national stability of the three-factor structure of the HEMA scale. In addition, it showed that the Bayesian approach is more informative than the traditional one, because it allows for more flexibility in model specification.},
  urldate = {2017-09-05TZ},
  journal = {Frontiers in Psychology},
  author = {Aleksandra Bujacz and Joar Vitters{\o} and Veronika Huta and Lukasz D. Kaczmarek},
  month = {sep},
  year = {2014},
  pmid = {25249997},
  pmcid = {PMC4157462},
}

@Misc{noauthor_tutorial_nodate,
  title = {A {Tutorial} on {Computing} {Bayes} {Factors} for {Single}-{Subject} {Designs}},
  url = {https://www.researchgate.net/publication/266799648_A_Tutorial_on_Computing_Bayes_Factors_for_Single-Subject_Designs},
  abstract = {ResearchGate is a network dedicated to science and research. Connect, collaborate and discover scientific publications, jobs and conferences. All for free.},
  urldate = {2017-07-05TZ},
  journal = {ResearchGate},
}

@Article{pires_assessing_2010,
  title = {Assessing the differences in public health impact of salmonella subtypes using a bayesian microbial subtyping approach for source attribution},
  volume = {7},
  issn = {1556-7125},
  doi = {10.1089/fpd.2009.0369},
  abstract = {Salmonella is a major cause of human gastroenteritis worldwide. To prioritize interventions and assess the effectiveness of efforts to reduce illness, it is important to attribute salmonellosis to the responsible sources. Studies have suggested that some Salmonella subtypes have a higher health impact than others. Likewise, some food sources appear to have a higher impact than others. Knowledge of variability in the impact of subtypes and sources may provide valuable added information for research, risk management, and public health strategies. We developed a Bayesian model that attributes illness to specific sources and allows for a better estimation of the differences in the ability of Salmonella subtypes and food types to result in reported salmonellosis. The model accommodates data for multiple years and is based on the Danish Salmonella surveillance. The number of sporadic cases caused by different Salmonella subtypes is estimated as a function of the prevalence of these subtypes in the animal-food sources, the amount of food consumed, subtype-related factors, and source-related factors. Our results showed relative differences between Salmonella subtypes in their ability to cause disease. These differences presumably represent multiple factors, such as differences in survivability through the food chain and/or pathogenicity. The relative importance of the source-dependent factors varied considerably over the years, reflecting, among others, variability in the surveillance programs for the different animal sources. The presented model requires estimation of fewer parameters than a previously developed model, and thus allows for a better estimation of these factors to result in reported human disease. In addition, a comparison of the results of the same model using different sets of typing data revealed that the model can be applied to data with less discriminatory power, which is the only data available in many countries. In conclusion, the model allows for the estimation of relative differences between Salmonella subtypes and sources, providing results that will benefit future risk assessment or risk ranking purposes.},
  language = {eng},
  number = {2},
  journal = {Foodborne pathogens and disease},
  author = {Sara M. Pires and Tine Hald},
  month = {feb},
  year = {2010},
  pmid = {19877767},
  pages = {143--51},
}

@Article{hayashi_bayesian_2011,
  title = {A {Bayesian} approach to probabilistic ecological risk assessment: risk comparison of nine toxic substances in {Tokyo} surface waters},
  volume = {18},
  issn = {1614-7499},
  doi = {10.1007/s11356-010-0380-5},
  abstract = {BACKGROUND, AIM, AND SCOPE: Quantitative risk comparison of toxic substances is necessary to decide which substances should be prioritized to achieve effective risk management. This study compared the ecological risk among nine major toxic substances (ammonia, bisphenol-A, chloroform, copper, hexavalent chromium, lead, manganese, nickel, and zinc) in Tokyo surface waters by adopting an integrated risk analysis procedure using Bayesian statistics. METHODS: Species sensitivity distributions of these substances were derived by using four Bayesian models. Environmental concentration distributions were derived by a hierarchical Bayesian model that explicitly considered the differences between within-site and between-site variations in environmental concentrations. Medians and confidence intervals of the expected potentially affected fraction (EPAF) of species were then computed by the Monte Carlo method. RESULTS: The estimated EPAF values suggested that risk from nickel was highest and risk from zinc and ammonia were also high relative to other substances. The risk from copper was highest if bioavailability was not considered, although toxicity correction by a biotic ligand model greatly reduced the estimated risk. The risk from manganese was highest if a conservative risk index estimate (90\% upper EPAF confidence limit) was selected. CONCLUSION: It is suggested that zinc is not a predominant risk factor in Tokyo surface waters and strategic efforts are required to reduce the total ecological risk from multiple substances. The presented risk analysis procedure using EPAF and Bayesian statistics is expected to advance methodologies and practices in quantitative ecological risk comparison.},
  language = {eng},
  number = {3},
  journal = {Environmental science and pollution research international},
  author = {Takehiko I. Hayashi and Nobuhisa Kashiwagi},
  month = {mar},
  year = {2011},
  pmid = {20686862},
  pages = {365--75},
}

@Article{kaufman_flexible_2011,
  title = {A flexible {Bayesian} hierarchical model of preterm birth risk among {US} {Hispanic} subgroups in relation to maternal nativity and education},
  volume = {11},
  issn = {1471-2288},
  doi = {10.1186/1471-2288-11-51},
  abstract = {BACKGROUND: Previous research has documented heterogeneity in the effects of maternal education on adverse birth outcomes by nativity and Hispanic subgroup in the United States. In this article, we considered the risk of preterm birth (PTB) using 9 years of vital statistics birth data from New York City. We employed finer categorizations of exposure than used previously and estimated the risk dose-response across the range of education by nativity and ethnicity. METHODS: Using Bayesian random effects logistic regression models with restricted quadratic spline terms for years of completed maternal education, we calculated and plotted the estimated posterior probabilities of PTB (gestational age {\textless} 37 weeks) for each year of education by ethnic and nativity subgroups adjusted for only maternal age, as well as with more extensive covariate adjustments. We then estimated the posterior risk difference between native and foreign born mothers by ethnicity over the continuous range of education exposures. RESULTS: The risk of PTB varied substantially by education, nativity and ethnicity. Native born groups showed higher absolute risk of PTB and declining risk associated with higher levels of education beyond about 10 years, as did foreign-born Puerto Ricans. For most other foreign born groups, however, risk of PTB was flatter across the education range. For Mexicans, Central Americans, Dominicans, South Americans and {"}Others{"}, the protective effect of foreign birth diminished progressively across the educational range. Only for Puerto Ricans was there no nativity advantage for the foreign born, although small numbers of foreign born Cubans limited precision of estimates for that group. CONCLUSIONS: Using flexible Bayesian regression models with random effects allowed us to estimate absolute risks without strong modeling assumptions. Risk comparisons for any sub-groups at any exposure level were simple to calculate. Shrinkage of posterior estimates through the use of random effects allowed for finer categorization of exposures without restricting joint effects to follow a fixed parametric scale. Although foreign born Hispanic women with the least education appeared to generally have low risk, this seems likely to be a marker for unmeasured environmental and behavioral factors, rather than a causally protective effect of low education itself.},
  language = {eng},
  journal = {BMC medical research methodology},
  author = {Jay S. Kaufman and Richard F. MacLehose and Elizabeth A. Torrone and David A. Savitz},
  month = {apr},
  year = {2011},
  pmid = {21504612},
  pages = {51},
}

@Article{boelter_bayesian_2016,
  title = {A {Bayesian} {Model} and {Stochastic} {Exposure} ({Dose}) {Estimation} for {Relative} {Exposure} {Risk} {Comparison} {Involving} {Asbestos}-{Containing} {Dropped} {Ceiling} {Panel} {Installation} and {Maintenance} {Tasks}},
  issn = {1539-6924},
  doi = {10.1111/risa.12733},
  abstract = {Assessing exposures to hazards in order to characterize risk is at the core of occupational hygiene. Our study examined dropped ceiling systems commonly used in schools and commercial buildings and lay-in ceiling panels that may have contained asbestos prior to the mid to late 1970s. However, most ceiling panels and tiles do not contain asbestos. Since asbestos risk relates to dose, we estimated the distribution of eight-hour TWA concentrations and one-year exposures (a one-year dose equivalent) to asbestos fibers (asbestos f/cc-years) for five groups of workers who may encounter dropped ceilings: specialists, generalists, maintenance workers, nonprofessional do-it-yourself (DIY) persons, and other tradespersons who are bystanders to ceiling work. Concentration data (asbestos f/cc) were obtained through two exposure assessment studies in the field and one chamber study. Bayesian and stochastic models were applied to estimate distributions of eight-hour TWAs and annual exposures (dose). The eight-hour TWAs for all work categories were below current and historic occupational exposure limits (OELs). Exposures to asbestos fibers from dropped ceiling work would be categorized as {"}highly controlled{"} for maintenance workers and {"}well controlled{"} for remaining work categories, according to the American Industrial Hygiene Association exposure control rating system. Annual exposures (dose) were found to be greatest for specialists, followed by maintenance workers, generalists, bystanders, and DIY. On a comparative basis, modeled dose and thus risk from dropped ceilings for all work categories were orders of magnitude lower than published exposures for other sources of banned friable asbestos-containing building material commonly encountered in construction trades.},
  language = {eng},
  journal = {Risk analysis : an official publication of the Society for Risk Analysis},
  author = {Fred W. Boelter and Yulin Xia and Jacob D. Persky},
  month = {nov},
  year = {2016},
  pmid = {27862114},
}

@Article{wang_accident_2013,
  title = {Accident analysis model based on {Bayesian} {Network} and {Evidential} {Reasoning} approach},
  volume = {26},
  issn = {0950-4230},
  url = {http://www.sciencedirect.com/science/article/pii/S0950423012001301},
  doi = {10.1016/j.jlp.2012.08.001},
  abstract = {In this paper, an accident analysis model is proposed to develop the cost-efficient safety measures for preventing accidents. The model comprises two parts. In the first part, a quantitative accident analysis model is built by integrating Human Factors Analysis and Classification System (HFACS) with Bayesian Network (BN), which can be utilized to present the corresponding prevention measures. In the second part, the proposed prevention measures are ranked in a cost-effectiveness manner through Best-Fit method and Evidential Reasoning (ER) approach. A case study of vessel collision is analyzed as an illustration. The case study shows that the proposed model can be used to seek out accident causes and rank the derived safety measures from a cost-effectiveness perspective. The proposed model can provide accident investigators with a tool to generate cost-efficient safety intervention strategies.},
  number = {1},
  journal = {Journal of Loss Prevention in the Process Industries},
  author = {Yan Fu Wang and Min Xie and Kwai-Sang Chin and Xiu Ju Fu},
  month = {jan},
  year = {2013},
  keywords = {Accident analysis model, Bayesian Network (BN), Evidential Reasoning (ER) approach, Human Factors Analysis and Classification System (HFACS)},
  pages = {10--21},
}

@Article{yeo_dynamic_2016,
  title = {Dynamic risk analysis of offloading process in floating liquefied natural gas ({FLNG}) platform using {Bayesian} {Network}},
  volume = {41},
  issn = {0950-4230},
  url = {http://www.sciencedirect.com/science/article/pii/S0950423016300870},
  doi = {10.1016/j.jlp.2016.04.002},
  abstract = {Abstract
The growing demand for natural gas has pushed oil and gas exploration to more isolated and previously untapped regions around the world where construction of LNG processing plants is not always a viable option. The development of FLNG will allow floating plants to be positioned in remote offshore areas and subsequently produce, liquefy, store and offload LNG in the one position. The offloading process from an FLNG platform to a gas tanker can be a high risk operation. It consists of LNG being transferred, in hostile environments, through loading arms or flexible cryogenic hoses into a carrier which then transports the LNG to onshore facilities. During the carrier's offloading process at onshore terminals, it again involves risk that may result in an accident such as collision, leakage and/or grounding. It is therefore critical to assess and monitor all risks associated with the offloading operation. This study is aimed at developing a novel methodology using Bayesian Network (BN) to conduct the dynamic safety analysis for the offloading process of an LNG carrier. It investigates different risk factors associated with LNG offloading procedures in order to predict the probability of undesirable accidents. Dynamic failure assessment using Bayesian theory can estimate the likelihood of the occurrence of an event. It can also estimate the failure probability of the safety system and thereby develop a dynamic failure assessment tool for the offloading process at a particular FLNG plant. The main objectives of this paper are: to understand the LNG offloading process, to identify hazardous events during offloading operation, and to perform failure analysis (modelling) of critical accidents and/or events. Most importantly, it is to evaluate and compare risks. A sensitivity analysis has been performed to validate the risk models and to study the behaviour of the most influential factors. The results have indicated that collision is the most probable accident to occur during the offloading process of an LNG carrier at berth, which may have catastrophic consequences.},
  journal = {Journal of Loss Prevention in the Process Industries},
  author = {ChuiTing Yeo and Jyoti Bhandari and Rouzbeh Abbassi and Vikram Garaniya and Shuhong Chai and Behzad Shomali},
  month = {may},
  year = {2016},
  keywords = {Accident, Bayesian network, Dynamic risk analysis, FLNG, Safety barriers},
  pages = {259--269},
}

@Article{bhandari_risk_2015,
  title = {Risk analysis of deepwater drilling operations using {Bayesian} network},
  volume = {38},
  issn = {0950-4230},
  url = {http://www.sciencedirect.com/science/article/pii/S0950423015300188},
  doi = {10.1016/j.jlp.2015.08.004},
  abstract = {Abstract
Deepwater drilling is one of the high-risk operations in the oil and gas sector due to large uncertainties and extreme operating conditions. In the last few decades Managed Pressure Drilling Operations (MPD) and Underbalanced Drilling (UBD) have become increasingly used as alternatives to conventional drilling operations such as Overbalanced Drilling (OVD) technology. These newer techniques provide several advantages however the blowout risk during these operations is still not fully understood. Blowout is regarded as one of the most catastrophic events in offshore drilling operations; therefore implementation and maintenance of safety measures is essential to maintain risk below the acceptance criteria. This study is aimed at applying the Bayesian Network (BN) to conduct a dynamic safety analysis of deepwater MPD and UBD operations. It investigates different risk factors associated with MPD and UBD technologies, which could lead to a blowout accident. Blowout accident scenarios are investigated and the BNs are developed for MPD and UBD technologies in order to predict the probability of blowout occurrence. The main objective of this paper is to understand MPD and UBD technologies, to identify hazardous events during MPD and UBD operations, to perform failure analysis (modelling) of blowout events and to evaluate plus compare risk. Importance factor analysis in drilling operations is performed to assess contribution of each root cause to the potential accident; the results show that UBD has a higher occurrence probability of kick and blowout compared to MPD technology. The Rotating Control Devices (RCD) failure in MPD technology and increase in flow-through annulus in UBD technology are the most critical situations for kick and blowout.},
  journal = {Journal of Loss Prevention in the Process Industries},
  author = {Jyoti Bhandari and Rouzbeh Abbassi and Vikram Garaniya and Faisal Khan},
  month = {nov},
  year = {2015},
  keywords = {Bayesian network, Blowout, Dynamic risk analysis, Kick, Managed pressure drilling},
  pages = {11--23},
}

@Article{dey_new_1991,
  title = {A new empirical {Bayes} estimator with type {II} censored data},
  volume = {12},
  issn = {0167-9473},
  url = {http://www.sciencedirect.com/science/article/pii/016794739190111E},
  doi = {10.1016/0167-9473(91)90111-E},
  abstract = {Estimation of the scale parameter in a Weibull, Raleigh or an exponential distribution with type II censored data is considered. A new class of empirical Bayes estimators, which expands the present estimator by a multiple of the geometric mean of the component estimators, is developed. The exact risk improvement over the best multiple estimator is obtained. A numerical example is given to compare our empirical Bayes estimates with two others existing in the literature. The risk comparison among the three estimators is also evaluated by Monte Carlo methods.},
  number = {3},
  journal = {Computational Statistics \& Data Analysis},
  author = {Dipak K. Dey and Lynn Kuo},
  month = {nov},
  year = {1991},
  keywords = {Exponential distribution, Gamma distribution, Life testing, Scale parameter, Simultaneous estimation, Weibull distribution},
  pages = {271--279},
}

@Misc{noauthor_effect_nodate,
  title = {An effect size measure and {Bayesian} analysis of single-case designs},
  url = {https://www.researchgate.net/publication/260644494_An_effect_size_measure_and_Bayesian_analysis_of_single-case_designs},
  abstract = {ResearchGate is a network dedicated to science and research. Connect, collaborate and discover scientific publications, jobs and conferences. All for free.},
  urldate = {2017-07-13TZ},
  journal = {ResearchGate},
}

@Article{shadish_bayesian_2013,
  title = {Bayesian estimates of autocorrelations in single-case designs},
  volume = {45},
  issn = {1554-3528},
  url = {https://link.springer.com/article/10.3758/s13428-012-0282-1},
  doi = {10.3758/s13428-012-0282-1},
  abstract = {Researchers in the single-case design tradition have debated the size and importance of the observed autocorrelations in those designs. All of the past estimates of the autocorrelation in that literature have taken the observed autocorrelation estimates as the data to be used in the debate. However, estimates of the autocorrelation are subject to great sampling error when the design has a small number of time points, as is typically the situation in single-case designs. Thus, a given observed autocorrelation may greatly over- or underestimate the corresponding population parameter. This article presents Bayesian estimates of the autocorrelation that greatly reduce the role of sampling error, as compared to past estimators. Simpler empirical Bayes estimates are presented first, in order to illustrate the fundamental notions of autocorrelation sampling error and shrinkage, followed by fully Bayesian estimates, and the difference between the two is explained. Scripts to do the analyses are available as supplemental materials. The analyses are illustrated using two examples from the single-case design literature. Bayesian estimation warrants wider use, not only in debates about the size of autocorrelations, but also in statistical methods that require an independent estimate of the autocorrelation to analyze the data.},
  language = {en},
  number = {3},
  urldate = {2017-07-05TZ},
  journal = {Behavior Research Methods},
  author = {William R. Shadish and David M. Rindskopf and Larry V. Hedges and Kristynn J. Sullivan},
  month = {sep},
  year = {2013},
  pages = {813--821},
}

@Article{ozechowski_empirical_2014,
  title = {Empirical {Bayes} {MCMC} estimation for modeling treatment processes, mechanisms of change, and clinical outcomes in small samples.},
  volume = {82},
  issn = {1939-2117, 0022-006X},
  url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/a0035889},
  doi = {10.1037/a0035889},
  language = {en},
  number = {5},
  urldate = {2015-07-02TZ},
  journal = {Journal of Consulting and Clinical Psychology},
  author = {Timothy J. Ozechowski},
  year = {2014},
  pages = {854--867},
}

@Article{depaoli_linear_2014,
  title = {Linear and nonlinear growth models: {Describing} a {Bayesian} perspective.},
  volume = {82},
  issn = {1939-2117, 0022-006X},
  shorttitle = {Linear and nonlinear growth models},
  url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/a0035147},
  doi = {10.1037/a0035147},
  language = {en},
  number = {5},
  urldate = {2015-07-02TZ},
  journal = {Journal of Consulting and Clinical Psychology},
  author = {Sarah Depaoli and Jonathan Boyajian},
  year = {2014},
  pages = {784--802},
}
